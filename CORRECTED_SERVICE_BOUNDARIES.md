# Corrected Service Boundaries

## The Confusion

I was mixing concerns! Let me separate clearly:

---

## Service Separation

### 1. `knowledge_cache_engine` (NIF)
**Purpose:** Cache **code knowledge** only
**NOT for:** LLM configs, system prompts, or AI-related stuff

**What belongs:**
- âœ… Code patterns (async-worker, auth-handler)
- âœ… Code templates (GenServer, Axum API)
- âœ… Framework configs (Phoenix detection rules)
- âœ… Package metadata (npm/cargo/hex registry)
- âœ… Quality rules (Credo, Clippy configs)

**What does NOT belong:**
- âŒ LLM system prompts â†’ `prompt_engine`
- âŒ LLM configs â†’ `prompt_engine`
- âŒ AI workflows â†’ `agent service`

---

### 2. `prompt_engine` / `prompt_intelligence` (NIF)
**Purpose:** Handle ALL prompt/LLM-related intelligence
**From:** `rust-central/prompt_intelligence/`

**What belongs:**
- âœ… LLM system prompts
- âœ… LLM model configs (temperature, max_tokens)
- âœ… Prompt templates
- âœ… Prompt optimization (DSPy)
- âœ… Prompt caching
- âœ… Prompt performance tracking

**Storage:**
```rust
// prompt_intelligence has its own cache!
// Location: rust-central/prompt_intelligence/src/lib.rs

static PROMPT_CACHE: Lazy<Prompt.Cache> = Lazy::new(|| {
    Prompt.Cache::new()
});

#[rustler::nif]
fn get_system_prompt(task_type: String) -> NifResult<String> {
    // Check prompt cache first
    if let Some(prompt) = PROMPT_CACHE.get(&task_type) {
        return Ok(prompt);
    }

    // Fallback: load from database
    load_prompt_from_db(&task_type)
}
```

---

### 3. `knowledge_central_service` (NATS Service)
**Purpose:** Central hub for **code knowledge only**

**What it handles:**
- âœ… Code patterns, templates
- âœ… Package metadata
- âœ… Framework knowledge
- âœ… Quality rules

**What it does NOT handle:**
- âŒ LLM prompts â†’ `prompt_intelligence` handles locally
- âŒ AI workflows â†’ Separate agent services

---

## Corrected Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Application Layer                            â”‚
â”‚                                                                  â”‚
â”‚  Code Knowledge              LLM/Prompt Intelligence            â”‚
â”‚  â†“                           â†“                                  â”‚
â”‚  KnowledgeCache              PromptEngine                       â”‚
â”‚  .get("pattern:...")         .get_system_prompt("code-gen")    â”‚
â”‚  .get("package:...")         .optimize_prompt(...)             â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                                â”‚
          â”‚ NIF call                       â”‚ NIF call
          â–¼                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ knowledge_cache_engine  â”‚   â”‚ prompt_intelligence          â”‚
â”‚ (Code knowledge NIF)    â”‚   â”‚ (Prompt/LLM NIF)            â”‚
â”‚                         â”‚   â”‚                              â”‚
â”‚ â€¢ Patterns              â”‚   â”‚ â€¢ System prompts            â”‚
â”‚ â€¢ Templates             â”‚   â”‚ â€¢ Prompt templates          â”‚
â”‚ â€¢ Package metadata      â”‚   â”‚ â€¢ DSPy optimization         â”‚
â”‚ â€¢ Framework configs     â”‚   â”‚ â€¢ Prompt cache              â”‚
â”‚                         â”‚   â”‚                              â”‚
â”‚ NATS â†’ central (miss)   â”‚   â”‚ PostgreSQL (local)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                                â”‚
          â”‚ On miss                        â”‚ (self-contained)
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ knowledge_central_svc   â”‚
â”‚ (Code knowledge hub)    â”‚
â”‚                         â”‚
â”‚ â€¢ PostgreSQL            â”‚
â”‚ â€¢ npm/cargo/hex APIs    â”‚
â”‚ â€¢ Broadcast updates     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Corrected Routing Table

### Code Knowledge â†’ `KnowledgeCache` â†’ `knowledge_central`

| Type | Example | Why |
|------|---------|-----|
| **Code Pattern** | `pattern:async-worker` | Code reuse |
| **Code Template** | `template:genserver` | Scaffolding |
| **Package Info** | `package:npm:react` | Registry metadata |
| **Framework Config** | `framework:phoenix:rules` | Detection |
| **Quality Rules** | `quality:credo:config` | Linting |

### LLM/Prompt â†’ `PromptEngine` (Self-Contained)

| Type | How It Works | Why |
|------|--------------|-----|
| **System Prompt** | `PromptEngine.get_system_prompt("code-gen")` | Prompt-specific logic |
| **Prompt Template** | `PromptEngine.get_template("refactor")` | DSPy integration |
| **Prompt Optimization** | `PromptEngine.optimize(prompt)` | ML-based |
| **Prompt Cache** | Internal to `prompt_intelligence` NIF | Self-managed |

### Dynamic Requests â†’ Direct NATS

| Type | Route | Why |
|------|-------|-----|
| **LLM Call** | `ai.llm.request` | Unique per call |
| **Code Analysis** | `code.analysis.*` | Unique per file |
| **Agent Execute** | `agents.execute` | Stateful |

---

## Why Separate?

### `knowledge_cache_engine` = Static Code Knowledge
```elixir
# These are about CODE, not AI/LLM
KnowledgeCache.get("pattern:async-worker")
KnowledgeCache.get("package:npm:react")
KnowledgeCache.get("framework:phoenix:detection")
```

**Characteristics:**
- Domain: Code, packages, frameworks
- Changes: Rarely (weeks/months)
- Source: Git, package registries, manual curation
- Size: 100-1000 entries

### `prompt_intelligence` = LLM/Prompt Intelligence
```elixir
# These are about PROMPTS/LLM, not code knowledge
PromptEngine.get_system_prompt("code-generation")
PromptEngine.optimize_prompt(user_prompt)
PromptEngine.get_template("refactor")
```

**Characteristics:**
- Domain: LLM, prompts, AI optimization
- Changes: Frequently (days) as we optimize
- Source: DSPy learning, A/B testing, manual tuning
- Size: 20-100 prompts
- **Has its own cache/optimization** (DSPy, redb)

---

## No Overlap!

### âŒ WRONG: System Prompts in Knowledge Cache
```elixir
# DON'T DO THIS
KnowledgeCache.get("llm:codex:system-prompt")
# â†‘ Wrong domain! knowledge_cache is for CODE knowledge
```

### âœ… CORRECT: System Prompts in Prompt Engine
```elixir
# DO THIS
PromptEngine.get_system_prompt("code-generation")
# â†‘ Right domain! prompt_engine handles ALL prompt logic
```

---

## Storage Locations

### Code Knowledge
```
L1: knowledge_cache_engine.so (NIF HashMap)
L2: PostgreSQL knowledge_artifacts table (local)
L3: knowledge_central_service (NATS) â†’ PostgreSQL (central)
```

### Prompt Intelligence
```
L1: prompt_intelligence.so (NIF with redb)
L2: PostgreSQL prompt_templates table (local)
No L3: Self-contained! No central service needed
```

### LLM Calls
```
No cache: Every call unique, goes direct to ai.llm.request
```

---

## Summary

### Question: "You sure it's knowledge for system prompts? Compare to prompt_engine and other central services."

**Answer: NO! You're right - system prompts belong in `prompt_engine`, not `knowledge_cache`!**

### Corrected Boundaries:

| Service | Domain | Examples |
|---------|--------|----------|
| **knowledge_cache_engine** | Code knowledge | Patterns, templates, packages |
| **prompt_intelligence** | LLM/Prompt intelligence | System prompts, DSPy optimization |
| **knowledge_central** | Code knowledge hub | Central repo for patterns/templates |
| **ai-server** | LLM execution | Actual LLM calls (Claude, Codex) |

### No Overlap:
- `knowledge_cache` = Code stuff
- `prompt_engine` = Prompt/LLM stuff
- `ai-server` = Execution

Clean separation! ğŸ¯

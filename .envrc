dotenv_if_exists .env
dotenv_if_exists .envrc.local
use flake .#dev

# Add bun to PATH (for bunx and other bun commands)
export PATH="${HOME}/.bun/bin:/nix/store/6fawnsgy0s773hhxrf6jxgfg8xqlshi7-bun-1.3.0/bin:${PATH}"

# Configure bun for better caching and performance
export BUN_INSTALL_CACHE_DIR="${STATE_DIR}/.bun-cache"
export BUN_TMPDIR="${TMPDIR:-/tmp}"

# Standard defaults (override by setting the variable before entering direnv)
export NIXPKGS_ALLOW_UNFREE="${NIXPKGS_ALLOW_UNFREE:-1}"

if [ -z "${NIX_BUILD_CORES:-}" ]; then
        export NIX_BUILD_CORES="$(nproc)"
fi

export MIX_ENV="${MIX_ENV:-dev}"

# Fix Erlang scheduler binding for macOS
export ELIXIR_ERL_OPTIONS="+fnu +sbt u"

STATE_DIR="${STATE_DIR:-$HOME/.local/share/singularity}"
export STATE_DIR
export MIX_HOME="${MIX_HOME:-$STATE_DIR/.mix}"
export HEX_HOME="${HEX_HOME:-$STATE_DIR/.hex}"

# Auto-detect GitHub token from gh CLI
if command -v gh >/dev/null 2>&1 && [ -z "${GITHUB_TOKEN:-}" ]; then
        GITHUB_TOKEN=$(gh auth token 2>/dev/null || true)
        if [ -n "$GITHUB_TOKEN" ]; then
                export GITHUB_TOKEN
        fi
fi

# Google Gemini Code Assist - uses @google/gemini-cli-core OAuth
# Both gemini_code_api and gemini_code_cli use the same OAuth credentials
# No gcloud SDK needed - auth handled by gemini-cli-core library

DEFAULT_GEMINI_PROJECT="gemini-code-473918"
if [ -z "${GEMINI_CODE_PROJECT:-}" ]; then
        export GEMINI_CODE_PROJECT="$DEFAULT_GEMINI_PROJECT"
fi

if [ -z "${GOOGLE_CLOUD_PROJECT:-}" ]; then
        export GOOGLE_CLOUD_PROJECT="$GEMINI_CODE_PROJECT"
fi

if [ -z "${CLOUDSDK_CORE_PROJECT:-}" ]; then
        export CLOUDSDK_CORE_PROJECT="$GEMINI_CODE_PROJECT"
fi

# Ensure Moonrepo CLI uses C.UTF-8 locale globally
export LC_ALL=C.UTF-8
export LANG=C.UTF-8

# Singularity Unified Build Cache Configuration
# Shared cache directories for ALL build systems coordinated by moonrepo

# === RUST/CARGO DEPENDENCY & BUILD CACHING ===
# Shared cargo dependencies across all projects (crates.io downloads)
export CARGO_HOME="${HOME}/.cache/singularity/cargo"

# sccache for distributed Rust compilation caching
export SCCACHE_DIR="${HOME}/.cache/singularity/sccache"
export SCCACHE_CACHE_SIZE="10G"
export RUSTC_WRAPPER="sccache"  # Enable sccache for all Rust builds

# Cargo build artifacts (local per-project for isolation, but deps are shared via CARGO_HOME)
export CARGO_TARGET_DIR=".cargo-build"
export CARGO_INCREMENTAL="0"  # Disabled for sccache compatibility

# === BUN DEPENDENCY & BUILD CACHING ===
# Shared bun dependencies across all projects (npm packages)
export BUN_INSTALL_CACHE_DIR="${BUN_INSTALL_CACHE_DIR:-$STATE_DIR/.bun-cache}"
export BUN_INSTALL_GLOBAL_DIR="${BUN_INSTALL_GLOBAL_DIR:-$STATE_DIR/.bun-global}"

# === NODE.JS/NPM CACHING (if fallback from bun) ===
export npm_config_cache="${HOME}/.cache/singularity/npm"

# === MOON CACHING ===
# Moon's workspace cache (task outputs, hashes)
export MOON_CACHE="${PWD}/.moon/cache"

# === TYPESCRIPT CACHING ===
# TypeScript build info cache
export TSC_CACHE_DIR="${HOME}/.cache/singularity/tsc"


# === BUILD PARALLELISM ===
# Unified parallel build jobs across all systems (6 cores)
NPROC=$(nproc)
export CARGO_BUILD_JOBS="${NPROC}"
export BUN_INSTALL_PARALLELISM="${NPROC}"

# === PERFORMANCE OPTIMIZATIONS ===
# Enable modern cargo sparse index (faster dependency resolution)
export CARGO_REGISTRIES_CRATES_IO_PROTOCOL="sparse"

# === LLM TRAINING DEFAULTS ===
export TORCH_CUDA_ARCH_LIST="${TORCH_CUDA_ARCH_LIST:-8.9}"
export BITSANDBYTES_NOWELCOME="${BITSANDBYTES_NOWELCOME:-1}"
export HF_HOME="${HF_HOME:-$STATE_DIR/.cache/huggingface}"
export TRANSFORMERS_CACHE="${TRANSFORMERS_CACHE:-$HF_HOME}"
export HF_DATASETS_CACHE="${HF_DATASETS_CACHE:-$HF_HOME/datasets}"

# Ensure Hugging Face caches exist
mkdir -p "${HF_HOME}" "${HF_DATASETS_CACHE}" 2>/dev/null || true

# === RUST LINKER CONFIGURATION ===
# Use default linker for compatibility
export RUSTFLAGS="-C linker=gcc"

# sccache is available via Nix flake (no hardcoded path needed)

# Create cache directories if they don't exist (quietly)
mkdir -p "${CARGO_HOME}" "${SCCACHE_DIR}" "${BUN_INSTALL_CACHE_DIR}" "${BUN_INSTALL_GLOBAL_DIR}" "${npm_config_cache}" "${TSC_CACHE_DIR}" 2>/dev/null || true

# Optional silent mode: export SINGULARITY_ENVRC_SILENT=1 to suppress banner
if [ -z "${SINGULARITY_ENVRC_SILENT}" ]; then
        echo "[OK] Singularity unified caching enabled:"
        echo "  Rust deps: ${CARGO_HOME}"
        echo "  Rust builds: sccache (${SCCACHE_DIR}, ${SCCACHE_CACHE_SIZE})"
        echo "  Bun deps: ${BUN_INSTALL_CACHE_DIR}"
        echo "  Moon tasks: ${MOON_CACHE}"
        echo "  Parallel: ${NPROC} cores"
fi

# Provide a helper to quickly silence in current shell: `export SINGULARITY_ENVRC_SILENT=1` then reload.

# === GOOGLE CHAT INTEGRATION ===
# Webhook URL for Singularity notifications (HITL approvals, error alerts, daily summaries)
# Google Chat webhook - load from .envrc.local (sensitive, git-ignored)
# export GOOGLE_CHAT_WEBHOOK_URL="..."
# export GOOGLE_CHAT_API_ENABLED="true"
# export GOOGLE_CHAT_SPACE_ID="..."
# export GOOGLE_CLOUD_PROJECT="..."

# === CACHIX BINARY CACHE ===
# Pull from public cache; no token required.
# For pushes, CACHIX_AUTH_TOKEN is auto-loaded from GitHub secrets above.
if command -v cachix >/dev/null 2>&1; then
  cachix use mikkihugo >/dev/null 2>&1 || true
fi

# === ERLANG/ELIXIR MEMORY LIMITS ===
# Limit BEAM VM memory (adjust based on your system)
export ERL_MAX_ETS_TABLES="${ERL_MAX_ETS_TABLES:-10000}"

# ERL_FLAGS Scheduler Binding Configuration (CRITICAL - macOS specific)
#
# âš ï¸  DO NOT CHANGE THIS VALUE - It is essential for macOS compatibility
#
# Explanation:
# - `-heart`: Enable heart monitoring for automatic restart on crashes
# - `+sbt u`: Scheduler binding type = "UNBOUND" (macOS only)
#   * Required for macOS (doesn't support cpu/db binding like Linux)
#   * NEVER change to +sbt db (causes "setting scheduler bind type 'db' failed: not supported")
#   * Linux users would use: +sbt db (database), +sbt s (spread)
# - `+sbwt very_long`: Scheduler busy wait threshold (tune for interactive use)
# - `+swt very_low`: Scheduler wait timeout (prevents CPU spinning)
#
# On macOS, ALWAYS use: `+sbt u` (unbound)
# On Linux, TYPICALLY use: `+sbt db` (for production) or `+sbt s` (for development)
export ERL_FLAGS="-heart +sbt u +sbwt very_long +swt very_low"

# Heap size limits (in words, 1 word = 8 bytes on 64-bit)
# Max 8GB heap per process, disable kill at max heap (we have memory!)
export ERL_AFLAGS="-kernel shell_history enabled +hmax 0 +hmaxk false"

# === HEX/MIX PRECOMPILED BINARY CONFIGURATION ===
# Prefer precompiled binaries over building from source
export HEX_UNSAFE_HTTPS="1"  # Allow HTTPS for precompiled binaries
export HEX_UNSAFE_REGISTRY="1"  # Trust registry for binaries
export HEX_HTTP_CONCURRENCY="8"  # Parallel downloads
export HEX_HTTP_TIMEOUT="300000"  # 5min timeout for large binaries
export MIX_XDG="1"  # Use XDG directories for cache
# Force EXLA to use precompiled binaries
# Auto-detects based on available GPU:
#   â€¢ CUDA available: Use cuda118 (RTX 4080 on Linux, or external NVIDIA GPU)
#   â€¢ Metal available: Use metal (macOS with Metal GPU - CoreML/MLX tasks)
#   â€¢ No GPU: CPU fallback (Linux without GPU, or older Macs)
# Note: EXLA doesn't support Metal (upstream limitation), but Metal can be used
#       for embeddings via CoreML/MLX and other GPU tasks
detect_xla_target() {
  if command -v nvidia-smi >/dev/null 2>&1; then
    echo "cuda118"  # CUDA is available
  elif [ "$(uname -s)" = "Darwin" ]; then
    echo "cpu"      # macOS - EXLA doesn't support Metal, use CPU
  else
    echo "cpu"      # No GPU - use CPU fallback
  fi
}
export XLA_TARGET="${XLA_TARGET:-$(detect_xla_target)}"
export EXLA_TARGET="${EXLA_TARGET:-$(detect_xla_target)}"  # EXLA also needs this variable
export EXLA_MODE="opt"  # Use optimized precompiled binaries

# === LOAD SECRETS ===
# Secrets are loaded from .envrc.local (git-ignored)
# Synced across environments using private GitHub Gist
#
# Setup (one-time):
#   ./scripts/sync-secrets.sh setup
#
# Sync secrets:
#   ./scripts/sync-secrets.sh push   # Upload to gist
#   ./scripts/sync-secrets.sh pull   # Download from gist
#
# .envrc.local is automatically loaded by direnv (see dotenv_if_exists at top of file)
#
# Auto-pull secrets from gist on new machines (if .gist_id exists)
if [ -f .gist_id ] && command -v gh >/dev/null 2>&1; then
  # Pull if .envrc.local doesn't exist (new machine)
  if [ ! -f .envrc.local ]; then
    echo "ðŸ“¥ Auto-syncing secrets from gist (new machine)..."
    ./scripts/sync-secrets.sh pull || true
  else
    # Check if gist has been updated (compare git commit hashes)
    GIST_ID=$(cat .gist_id 2>/dev/null)
    if [ -n "$GIST_ID" ]; then
      # Get local file hash
      LOCAL_HASH=$(sha256sum .envrc.local 2>/dev/null | cut -d' ' -f1 || shasum -a 256 .envrc.local 2>/dev/null | cut -d' ' -f1)
      # Get remote gist hash
      REMOTE_HASH=$(gh gist view "$GIST_ID" --raw --filename "envrc.local" 2>/dev/null | sha256sum 2>/dev/null | cut -d' ' -f1 || gh gist view "$GIST_ID" --raw --filename "envrc.local" 2>/dev/null | shasum -a 256 2>/dev/null | cut -d' ' -f1)

      if [ -n "$REMOTE_HASH" ] && [ "$LOCAL_HASH" != "$REMOTE_HASH" ]; then
        echo "ðŸ“¥ Secrets updated in gist! Auto-syncing..."
        ./scripts/sync-secrets.sh pull || true
      fi
    fi
  fi
fi

# === PHOENIX SECRET KEY BASE ===
# Required for Phoenix applications
# Override in .envrc.local for production secrets
export SECRET_KEY_BASE="${SECRET_KEY_BASE:-BNgh9981}"

# === DEVELOPMENT AUTO-INITIALIZATION ===
# Auto-initialize database and migrations on first entry to dev environment
if [ -x "$(command -v pg_isready)" ] && pg_isready -q 2>/dev/null; then
  # PostgreSQL is running, check if databases exist and auto-initialize
  if ! psql -l 2>/dev/null | grep -q "singularity"; then
    if [ -f "scripts/setup-database.sh" ]; then
      echo "[INFO] Auto-initializing databases..."
      bash scripts/setup-database.sh >/dev/null 2>&1 || true
    fi
  fi

  # Auto-run Ecto migrations for dev
  if [ -d "singularity_app" ] && [ -x "$(command -v mix)" ]; then
    cd singularity_app >/dev/null 2>&1 || true
    if [ -z "${SINGULARITY_SKIP_ECTO_MIGRATIONS:-}" ]; then
      mix ecto.create --quiet 2>/dev/null || true
      mix ecto.migrate --quiet 2>/dev/null || true
    fi
    cd - >/dev/null 2>&1 || true
  fi
fi

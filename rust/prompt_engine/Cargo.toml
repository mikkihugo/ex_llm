[package]
name = "prompt_engine"
version = "0.1.0"
edition = "2021"
license = "MIT OR Apache-2.0"
description = "AI prompt analysis and optimization suite for SPARC methodology"
repository = "https://github.com/claude-code-zen/zenflow"
readme = "README.md"
keywords = ["ai", "prompt", "optimization", "sparc", "engine"]
categories = ["development-tools", "ai"]

[dependencies]
anyhow = "1.0"
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
tokio = { version = "1.0", features = ["full"] }
futures = "0.3"
indexmap = "2.0"
uuid = { version = "1.8", features = ["v4", "serde"] }
async-trait = "0.1"
log = "0.4"
# Removed heavy ML dependencies - prompt engineering doesn't need neural networks
# Keep only DSPy for LLM-based prompt optimization
chrono = { version = "0.4", features = ["serde"] }
tempfile = "3"
toml = "0.8"
# redb removed - NIF doesn't need persistent storage
bincode = "1.3"
tracing = "0.1"
num_cpus = "1.16"
dirs = "5.0"
reqwest = { version = "0.11", features = ["json"] }
once_cell = "1.19"
walkdir = "2"

# Use templates provided by package_registry_indexer instead of embedding files (optional to avoid cycle)

# Optional ML dependencies (behind feature flag)
# Only Candle is used for neural networks - ndarray/smartcore removed to keep it lightweight
candle-core = { version = "0.9", optional = true }
candle-nn = { version = "0.9", optional = true }

# NATS messaging
async-nats = "0.33"

# Logging
tracing-subscriber = "0.3"

[dev-dependencies]
tokio = { version = "1.0", features = ["full"] }

[[bin]]
name = "prompt_analysis_service"
path = "src/bin/prompt_analysis_service.rs"

[features]
default = []
ml-analysis = ["candle-core", "candle-nn"]
with-package-indexer = []

# Workspace definition removed - now part of root workspace

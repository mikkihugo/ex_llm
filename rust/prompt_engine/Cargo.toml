[package]
name = "prompt-engine"
version = "0.1.0"
edition = "2021"
license = "MIT OR Apache-2.0"
description = "AI prompt engineering and optimization engine for SPARC methodology"
repository = "https://github.com/claude-code-zen/zenflow"
readme = "README.md"
keywords = ["ai", "prompt", "optimization", "sparc", "engine"]
categories = ["development-tools", "ai"]

[dependencies]
anyhow = { workspace = true }
serde = { workspace = true, features = ["derive"] }
serde_json = { workspace = true }
tokio = { workspace = true, features = ["full"] }
futures = { workspace = true }
indexmap = { workspace = true }
uuid = { workspace = true, features = ["v4", "serde"] }
async-trait = { workspace = true }
log = { workspace = true }
# Removed heavy ML dependencies - prompt engineering doesn't need neural networks
# Keep only DSPy for LLM-based prompt optimization
chrono = { workspace = true, features = ["serde"] }
tempfile = { workspace = true }
toml = { workspace = true }
redb = { workspace = true }
bincode = { workspace = true }
tracing = { workspace = true }
num_cpus = { workspace = true }
dirs = { workspace = true }
reqwest = { workspace = true, features = ["json"] }
once_cell = "1.19"

# Use templates provided by tool-doc-index instead of embedding files
tool_doc_index = { path = "../tool_doc_index", package = "tool-doc-index" }

# Optional ML dependencies (behind feature flag)
# Only Candle is used for neural networks - ndarray/smartcore removed to keep it lightweight
candle-core = { version = "0.8", optional = true }
candle-nn = { version = "0.8", optional = true }

[dev-dependencies]
tokio = { workspace = true, features = ["full"] }

[features]
default = []
ml-analysis = ["candle-core", "candle-nn"]

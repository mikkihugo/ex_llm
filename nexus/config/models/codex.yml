# Codex Provider Configuration
# ChatGPT Pro backend API access via OAuth2
#
# Authentication: OAuth2 tokens stored in PostgreSQL via Nexus.OAuthToken
# Base URL: https://chatgpt.com/backend-api
#
# Models available through ChatGPT Pro subscription (no per-token costs)

provider: codex
base_url: "https://chatgpt.com/backend-api"
authentication: oauth2
oauth_provider: chatgpt_pro

# Default model for medium/complex tasks
default_model: gpt-5-codex

models:
  # GPT-5 Codex - Advanced code generation model
  # Primary model for complex code generation and architecture tasks
  gpt-5-codex:
    name: "GPT-5 Codex"
    context_window: 272000  # 272K via ChatGPT Pro (192K via API)
    max_output_tokens: 128000
    pricing:
      input: 0.0      # Included in ChatGPT Pro subscription
      output: 0.0     # Included in ChatGPT Pro subscription
      currency: USD
    capabilities:
      - chat
      - streaming
      - code_generation
      - code_analysis
      - refactoring
      - debugging
      - function_calling
      - system_messages
    features:
      - Multi-language support (30+ languages)
      - Complex algorithm implementation
      - Code review and suggestions
      - Architecture design and patterns
      - Refactoring recommendations
      - Bug detection and fixes
    recommended_for:
      - Complex code generation
      - System architecture design
      - Algorithm implementation
      - Code refactoring
      - Debugging and troubleshooting
      - Production-quality code

  # GPT-5 - Advanced general-purpose model
  # Best for complex tasks beyond pure code generation
  gpt-5:
    name: "GPT-5"
    context_window: 400000  # 400K total (272K input + 128K output via API)
    max_input_tokens: 272000
    max_output_tokens: 128000
    pricing:
      input: 0.0      # Included in ChatGPT Pro subscription
      output: 0.0     # Included in ChatGPT Pro subscription
      currency: USD
    chatgpt_pro_limits:
      context_window: 128000  # ChatGPT Pro interface limit
    capabilities:
      - chat
      - streaming
      - code_generation
      - reasoning
      - function_calling
      - vision
      - system_messages
      - prompt_caching
    features:
      - Extended context window (200K)
      - Large output capacity (16K tokens)
      - Multi-modal understanding
      - Advanced reasoning capabilities
      - Complex problem decomposition
      - Mathematical reasoning
    recommended_for:
      - Complex reasoning tasks
      - Large context requirements
      - Multi-modal tasks
      - Planning and architecture
      - System design
      - Documentation generation

  # Codex Mini - Fast, lightweight code model
  # Optimized for speed and simple code tasks
  codex-mini-latest:
    name: "Codex Mini"
    context_window: 200000  # 200K context (128K for lighter tasks)
    max_output_tokens: 100000
    pricing:
      input: 1.5       # $1.50 per 1M input tokens (API pricing)
      output: 6.0      # $6.00 per 1M output tokens (API pricing)
      currency: USD
      prompt_caching_discount: 0.75  # 75% discount on cached prompts
      chatgpt_pro: 0.0  # Free with ChatGPT Pro subscription
    capabilities:
      - chat
      - streaming
      - code_generation
      - function_calling
      - vision
      - prompt_caching
      - structured_output
      - system_messages
      - reasoning
      - pdf_input
      - parallel_function_calling
      - tool_choice
    features:
      - Very large context (200K tokens)
      - Massive output capacity (100K tokens)
      - Fast inference
      - Vision support
      - PDF document processing
      - Structured output generation
    recommended_for:
      - Simple to medium code tasks
      - Fast responses needed
      - Large document processing
      - Vision-based code tasks
      - Batch code generation
      - API and tool integration
    mode: responses
    supported_endpoints:
      - /v1/responses
    supported_modalities:
      - text
      - image
    supported_output_modalities:
      - text

# Provider-specific settings
settings:
  # OAuth2 configuration
  oauth:
    token_storage: postgresql
    token_refresh: automatic
    token_expiry_buffer: 300  # Refresh 5 minutes before expiry

  # Rate limiting (ChatGPT Pro limits)
  rate_limits:
    requests_per_minute: 50
    requests_per_hour: 500
    tokens_per_minute: 100000

  # Request defaults
  defaults:
    temperature: 0.7
    max_tokens: 4096
    stream: false
    timeout: 60000  # 60 seconds

# Model selection by task complexity
# Used by Nexus.LLMRouter for intelligent routing
task_routing:
  simple:
    - codex-mini-latest
  medium:
    - gpt-5-codex
    - codex-mini-latest
  complex:
    - gpt-5-codex
    - gpt-5

  # Task type specific routing
  by_task_type:
    code_generation: gpt-5-codex
    architect: gpt-5
    refactoring: gpt-5-codex
    debugging: gpt-5-codex
    chat: codex-mini-latest
    vision: codex-mini-latest
    reasoning: gpt-5
    planning: gpt-5
    documentation: gpt-5
    simple_coding: codex-mini-latest
    analysis: gpt-5

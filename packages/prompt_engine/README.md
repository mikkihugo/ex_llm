# Prompt Engine - ML-Based Prompt Optimization

**Purpose**: Generic ML-powered prompt optimization using DSPy/COPRO. Domain-agnostic infrastructure for learning from execution history.

## ðŸŽ¯ What This Engine Does

1. **ML Optimization** - COPRO algorithm (generate 10 variants, pick best)
2. **Performance Tracking** - Learn from execution history via `prompt_tracking`
3. **Neural Training** - Candle-based ML models predict prompt success
4. **Context Assembly** - Combine templates + context for hyper-specific prompts

## ðŸ“Š Prompt Flow Architecture

### The Complete Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 1: TEMPLATE RETRIEVAL (Storage Layer)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Central Template Service (central_cloud)                      â”‚
â”‚    Location: central_cloud/lib/central_cloud/template_service.ex â”‚
â”‚    Storage: PostgreSQL (global, shared across instances)         â”‚
â”‚    Purpose: SINGLE SOURCE OF TRUTH for all templates             â”‚
â”‚                                                                   â”‚
â”‚    - Loads from templates_data/ on startup                       â”‚
â”‚    - Serves via NATS: central.template.{get|search|store}       â”‚
â”‚    - Tracks usage analytics for learning                         â”‚
â”‚    - Broadcasts updates to all instances                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 2: LOCAL OPTIMIZATION (prompt_engine - THIS CRATE)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Template Assembly (prompt_bits/)                              â”‚
â”‚    - Request template from CentralCloud via NATS                 â”‚
â”‚    - Inject context (language, framework, domain)                â”‚
â”‚    - Expand variables: {{language}}, {{framework}}, etc.         â”‚
â”‚    - Output: AssembledPrompt                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. ML Optimization (dspy/)                                       â”‚
â”‚    - COPRO generates 10 candidate variations                     â”‚
â”‚    - Neural net scores candidates (Candle ML)                    â”‚
â”‚    - Selects best based on learned patterns                      â”‚
â”‚    - Uses prompt_tracking historical data                        â”‚
â”‚    - Output: OptimizationResult                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Caching (caching/)                                            â”‚
â”‚    - Check PromptCache for similar context                       â”‚
â”‚    - Cache key: context_signature hash                           â”‚
â”‚    - Skip optimization if cached (performance)                   â”‚
â”‚    - Output: Cached or optimized prompt                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 3: EXECUTION & LEARNING                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Execution (external - sent to LLM)                            â”‚
â”‚    - Execute optimized prompt                                    â”‚
â”‚    - Measure: timing, success, response quality                  â”‚
â”‚    - Generate context_signature for tracking                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. Prompt Tracking (prompt_tracking/)                            â”‚
â”‚    - Store: PromptExecutionEntry (timing, success, confidence)   â”‚
â”‚    - Store: PromptFeedbackEntry (user ratings)                   â”‚
â”‚    - Store: PromptEvolutionEntry (optimization improvements)     â”‚
â”‚    - Store: ABTestResultEntry (A/B test results)                 â”‚
â”‚    - Communication: NATS â†’ PostgreSQL                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. Continuous Learning (dspy_learning/)                          â”‚
â”‚    - Query historical execution data                             â”‚
â”‚    - Train Candle neural network                                 â”‚
â”‚    - Update COPRO optimizer parameters                           â”‚
â”‚    - Improve future prompt generation                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸ”‘ Key Architectural Decisions

### Why Two Template Systems?

**Central Template Service** (central_cloud):
- âœ… **Global storage** - PostgreSQL (one copy, shared)
- âœ… **Source of truth** - All instances fetch from here
- âœ… **Analytics** - Tracks usage across all instances
- âœ… **Distribution** - NATS broadcasts updates
- **Purpose**: Storage & distribution

**Local Templates** (prompt_engine):
- âœ… **Hardcoded defaults** - System prompts, SPARC templates
- âœ… **No network needed** - Works offline for core functionality
- âœ… **Domain-specific** - SPARC methodology, Rust-specific
- âš ï¸ **Being phased out** - Move to central_cloud over time
- **Purpose**: Backwards compatibility & offline operation

### Template Types in This Crate

1. **`templates.rs`** (132 lines)
   - `PromptTemplate` struct - Generic template type
   - `RegistryTemplate` - In-memory template registry
   - `TemplateLoader` - Placeholder for loading (should use central_cloud)
   - **Status**: âš ï¸ Infrastructure only, move logic to central_cloud

2. **`sparc_templates.rs`** (466 lines)
   - SPARC methodology prompts (Specification, Architecture, etc.)
   - System behavior prompts (plan mode, beast mode, CLI mode)
   - Flow coordination prompts
   - **Status**: âœ… Keep - SPARC-specific, not domain templates

3. **`rust_dspy_templates.rs`** (565 lines)
   - Rust code analysis templates
   - DSPy prompt examples
   - **Status**: âš ï¸ Should move to central_cloud or architecture_engine

4. **`template_loader.rs`** (168 lines)
   - Loads templates from files
   - **Status**: âš ï¸ Redundant with central_cloud, remove

5. **`template_performance_tracker.rs`** (292 lines)
   - Tracks template performance with HTDAG
   - ML-driven template selection
   - **Status**: âœ… Keep - Performance/learning infrastructure

## ðŸ“ Example Usage

### Basic Flow

```rust
use prompt_engine::{PromptEngine, AssemblyContext};

// 1. Create engine
let mut engine = PromptEngine::new()?;

// 2. Fetch template from central_cloud (via NATS)
// This happens internally when you call optimize_prompt

// 3. Optimize with COPRO
let result = engine.optimize_prompt("Analyze this Rust code for bugs")?;

println!("Optimized: {}", result.optimized_prompt);
println!("Score: {}", result.optimization_score);
```

### With Context Assembly

```rust
// 1. Assemble with context
let context = AssemblyContext {
    language: "rust".to_string(),
    domain: "web_backend".to_string(),
    templates: vec!["axum_api".to_string()],
};

// 2. Get SPARC-specific prompt
let sparc_prompt = engine.get_optimized_sparc_prompt(
    "sparc_implementation",
    Some(hashmap!{
        "language" => "rust",
        "framework" => "axum"
    })
)?;
```

### With Tracking

```rust
use prompt_engine::prompt_tracking::{
    PromptTrackingStorage,
    PromptExecutionEntry,
    PromptExecutionData
};

// 1. Execute prompt
let start = Instant::now();
let response = llm.execute(&optimized_prompt).await?;
let duration = start.elapsed();

// 2. Track execution
let storage = PromptTrackingStorage::new_global().await?;
let entry = PromptExecutionEntry {
    prompt_id: "rust_analysis".to_string(),
    execution_time_ms: duration.as_millis() as u64,
    success: response.success,
    confidence_score: 0.9,
    context_signature: hash_context(&context),
    response_length: response.text.len(),
    timestamp: Utc::now(),
    metadata: HashMap::new(),
};

storage.store(PromptExecutionData::PromptExecution(entry)).await?;
```

## ðŸš€ What Makes It "An Engine"

1. **Self-improving** - Learns from every execution via neural training
2. **ML-powered** - Candle neural networks + DSPy optimizers
3. **Data-driven** - Queries historical patterns for decisions
4. **Adaptive** - Adjusts based on context (framework, domain, language)
5. **Distributed** - Learns across all instances via central_cloud

## ðŸ”„ Migration Path (TODOs)

### Short Term
- [ ] Move `rust_dspy_templates.rs` content to `central_cloud` PostgreSQL
- [ ] Remove `template_loader.rs` (use central_cloud NATS API instead)
- [ ] Update `RegistryTemplate` to fetch from NATS, not hardcoded

### Long Term
- [ ] Keep only `sparc_templates.rs` (SPARC methodology-specific)
- [ ] Keep `template_performance_tracker.rs` (learning infrastructure)
- [ ] Keep `templates.rs` types (generic structs)
- [ ] Remove all hardcoded domain templates

### Why Keep SPARC Templates Local?
- **Methodology-specific** - Not domain knowledge like "microservices"
- **Offline operation** - SPARC can work without central_cloud
- **Versioning** - SPARC templates version with prompt_engine code

## ðŸ“š Related Documentation

- **[UNIFIED_NIF_LOADING.md](../../UNIFIED_NIF_LOADING.md)** - How NIFs load
- **[RUST_ENGINES_INVENTORY.md](../../RUST_ENGINES_INVENTORY.md)** - All Rust engines
- **Prompt Tracking**: [prompt_tracking/mod.rs](src/prompt_tracking/mod.rs)
- **Central Template Service**: [central_cloud/lib/central_cloud/template_service.ex](../../central_cloud/lib/central_cloud/template_service.ex)

## ðŸŽ¯ Summary

**prompt_engine** = Generic ML optimization infrastructure
**central_cloud** = Global template storage & distribution
**architecture_engine** = Domain-specific templates (microservices, etc.)

Clean separation: Infrastructure vs Storage vs Domain Knowledge! ðŸŽ‰
